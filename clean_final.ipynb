{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Olympics Project\n",
    "Description: In this notebook, we construct a Decision Tree, Random Forest Classifier, Bagging, and Boosting models in attempt to model the data from the Olympics. \n",
    "### Authors: Kelvin Wang, Ethan Baird, Arnav Singh, Tuna Akmehmet"
   ],
   "id": "574f805d583acd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T20:12:52.504019Z",
     "start_time": "2024-08-16T20:12:52.125359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#importing data\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df = pd.read_csv(\"data/athlete_events.csv\") ## Here we have the raw .csv, feel free to download from Kaggle\n",
    "print(df.shape)"
   ],
   "id": "48b854d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271116, 15)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "e2b09257",
   "metadata": {
    "id": "e2b09257",
    "outputId": "39bfcb08-024a-45b1-b4cd-c38212e5b5d8",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:12:52.634616Z",
     "start_time": "2024-08-16T20:12:52.505481Z"
    }
   },
   "source": [
    "#subsetting\n",
    "# subset = df[['Sex', 'Age', 'Height', 'Weight', 'NOC', 'Year', 'Sport', 'Event', 'Medal']]\n",
    "# subset['Medal'].fillna('No Medal', inplace=True)\n",
    "# \n",
    "# \n",
    "# #Medal is 0 if they did not get a medal, 1 if they got bronze, silver, or gold\n",
    "# subset['Medal'] = subset['Medal'].apply(lambda x: 0 if x == 'No Medal' else 1)\n",
    "# \n",
    "# #Sex is 0 if male, 1 if female\n",
    "# subset['Sex'] = subset['Sex'].apply(lambda x: 0 if x == 'M' else 1)\n",
    "# \n",
    "# subset = subset.dropna()\n",
    "# \n",
    "# subset.shape\n",
    "\n",
    "###Better way without errors\n",
    "# Create a subset of the dataframe\n",
    "subset = df[['Sex', 'Age', 'Height', 'Weight', 'NOC', 'Year', 'Sport', 'Event', 'Medal']].copy()\n",
    "\n",
    "# Fill missing values in the 'Medal' column\n",
    "subset['Medal'] = subset['Medal'].fillna('No Medal')\n",
    "\n",
    "# Convert 'Medal' to 0 if no medal, 1 if any medal\n",
    "subset['Medal'] = subset['Medal'].apply(lambda x: 0 if x == 'No Medal' else 1)\n",
    "\n",
    "# Convert 'Sex' to 0 if male, 1 if female\n",
    "subset['Sex'] = subset['Sex'].apply(lambda x: 0 if x == 'M' else 1)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "subset = subset.dropna()\n",
    "\n",
    "# Display the first few rows of the modified subset, same size as before\n",
    "subset.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206165, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "9b6aa60e",
   "metadata": {
    "id": "9b6aa60e",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:12:52.637836Z",
     "start_time": "2024-08-16T20:12:52.635359Z"
    }
   },
   "source": [
    "def reduce_no_medal(df, n):\n",
    "    '''\n",
    "    :param df: the dataframe of the athlete events\n",
    "    :param n: The requested size to reduce the non-medal count too, in order to accurately compare to the medal count.\n",
    "    :return: the reduced_df with a more accurate size of medals vs. non-medals. We did this because size of non-medals is far greater than with medals\n",
    "    '''\n",
    "    no_medals = df[df['Medal'] == 0]\n",
    "    won_medals = df[df['Medal'] == 1]\n",
    "\n",
    "    no_medal_sample = no_medals.sample(n=n, random_state=42)\n",
    "\n",
    "    reduced_df = pd.concat([no_medal_sample, won_medals])\n",
    "\n",
    "    #shuffle the data, not sure if needed\n",
    "    reduced_df = reduced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return reduced_df"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "38cc6e4b",
   "metadata": {
    "id": "38cc6e4b",
    "outputId": "3fcc0fad-b950-4b73-8c9c-958fb8982b40",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:12:52.656680Z",
     "start_time": "2024-08-16T20:12:52.639462Z"
    }
   },
   "source": [
    "winners = subset[subset['Medal'] == 1]\n",
    "\n",
    "# Step 2: Group by Sport/Event and count the occurrences\n",
    "#sport_counts = medal_1_df['Sport'].value_counts()\n",
    "sport_counts = winners['Event'].value_counts() # In this case we choose event\n",
    "\n",
    "# Step 3: Filter to get events/sports with more than 20 entries, in order to get a good sample\n",
    "sports_with_more_than_20 = sport_counts[sport_counts > 50].index.tolist()\n",
    "\n",
    "#temp_subset = temp[temp['Sport'].isin(sports_with_more_than_20)]\n",
    "subset_enough_winners = subset[subset['Event'].isin(sports_with_more_than_20)]\n",
    "\n",
    "# Display the subset DataFrame\n",
    "subset_enough_winners.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107065, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "801e69e9",
   "metadata": {
    "id": "801e69e9",
    "outputId": "5d933bbe-abaf-4fbf-ba06-580d69d15661",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:12:52.675997Z",
     "start_time": "2024-08-16T20:12:52.657478Z"
    }
   },
   "source": [
    "#mean_weight_medal_1 = temp[temp['Medal'] == 1].groupby('Sport')['Height'].mean()\n",
    "mean_weight_medal_1 = subset_enough_winners[subset_enough_winners['Medal'] == 1].groupby('Event')['Height'].mean()\n",
    "\n",
    "# Group by Sport and calculate the mean Weight for Medal == 0\n",
    "#mean_weight_medal_0 = temp[temp['Medal'] == 0].groupby('Sport')['Height'].mean()\n",
    "mean_weight_medal_0 = subset_enough_winners[subset_enough_winners['Medal'] == 0].groupby('Event')['Height'].mean()\n",
    "\n",
    "# Display the results\n",
    "df1 = mean_weight_medal_1.to_frame(name='Mean_Weight_Medal_1')\n",
    "df2 = mean_weight_medal_0.to_frame(name='Mean_Weight_Medal_0')\n",
    "\n",
    "# Merge the two DataFrames on the 'Sport' index\n",
    "merged_df = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "\n",
    "merged_df[\"diff\"] = merged_df[\"Mean_Weight_Medal_1\"] - merged_df[\"Mean_Weight_Medal_0\"]\n",
    "\n",
    "merged_df.sort_values(by=\"diff\", ascending = True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 Mean_Weight_Medal_1  \\\n",
       "Event                                                                  \n",
       "Gymnastics Men's Floor Exercise                           165.274510   \n",
       "Gymnastics Men's Individual All-Around                    165.352941   \n",
       "Gymnastics Men's Horse Vault                              165.615385   \n",
       "Gymnastics Men's Team All-Around                          165.982877   \n",
       "Wrestling Men's Featherweight, Greco-Roman                164.714286   \n",
       "...                                                              ...   \n",
       "Swimming Women's 4 x 100 metres Freestyle Relay           175.461847   \n",
       "Rhythmic Gymnastics Women's Group                         171.420000   \n",
       "Swimming Men's 4 x 100 metres Freestyle Relay             190.467337   \n",
       "Cycling Men's 100 kilometres Team Time Trial              180.417476   \n",
       "Swimming Men's 100 metres Freestyle                       190.867925   \n",
       "\n",
       "                                                 Mean_Weight_Medal_0      diff  \n",
       "Event                                                                           \n",
       "Gymnastics Men's Floor Exercise                           167.676226 -2.401717  \n",
       "Gymnastics Men's Individual All-Around                    167.669123 -2.316182  \n",
       "Gymnastics Men's Horse Vault                              167.625000 -2.009615  \n",
       "Gymnastics Men's Team All-Around                          167.942632 -1.959755  \n",
       "Wrestling Men's Featherweight, Greco-Roman                166.044898 -1.330612  \n",
       "...                                                              ...       ...  \n",
       "Swimming Women's 4 x 100 metres Freestyle Relay           172.109306  3.352542  \n",
       "Rhythmic Gymnastics Women's Group                         168.030189  3.389811  \n",
       "Swimming Men's 4 x 100 metres Freestyle Relay             186.833583  3.633753  \n",
       "Cycling Men's 100 kilometres Team Time Trial              176.557542  3.859934  \n",
       "Swimming Men's 100 metres Freestyle                       185.169385  5.698539  \n",
       "\n",
       "[143 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Weight_Medal_1</th>\n",
       "      <th>Mean_Weight_Medal_0</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Event</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gymnastics Men's Floor Exercise</th>\n",
       "      <td>165.274510</td>\n",
       "      <td>167.676226</td>\n",
       "      <td>-2.401717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gymnastics Men's Individual All-Around</th>\n",
       "      <td>165.352941</td>\n",
       "      <td>167.669123</td>\n",
       "      <td>-2.316182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gymnastics Men's Horse Vault</th>\n",
       "      <td>165.615385</td>\n",
       "      <td>167.625000</td>\n",
       "      <td>-2.009615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gymnastics Men's Team All-Around</th>\n",
       "      <td>165.982877</td>\n",
       "      <td>167.942632</td>\n",
       "      <td>-1.959755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wrestling Men's Featherweight, Greco-Roman</th>\n",
       "      <td>164.714286</td>\n",
       "      <td>166.044898</td>\n",
       "      <td>-1.330612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swimming Women's 4 x 100 metres Freestyle Relay</th>\n",
       "      <td>175.461847</td>\n",
       "      <td>172.109306</td>\n",
       "      <td>3.352542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhythmic Gymnastics Women's Group</th>\n",
       "      <td>171.420000</td>\n",
       "      <td>168.030189</td>\n",
       "      <td>3.389811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swimming Men's 4 x 100 metres Freestyle Relay</th>\n",
       "      <td>190.467337</td>\n",
       "      <td>186.833583</td>\n",
       "      <td>3.633753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cycling Men's 100 kilometres Team Time Trial</th>\n",
       "      <td>180.417476</td>\n",
       "      <td>176.557542</td>\n",
       "      <td>3.859934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swimming Men's 100 metres Freestyle</th>\n",
       "      <td>190.867925</td>\n",
       "      <td>185.169385</td>\n",
       "      <td>5.698539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "44df8b9c",
   "metadata": {
    "id": "44df8b9c",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:46:26.770737Z",
     "start_time": "2024-08-16T20:46:26.749790Z"
    }
   },
   "source": [
    "# BEGINNING OF UI FOR SELECTION OF SPORT/EVENT\n",
    "###Creating a UI\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "model_data = None\n",
    "\n",
    "# Create a dropdown for selecting between \"Sport\" and \"Event\"\n",
    "category_dropdown = widgets.Dropdown(\n",
    "    options=[\"Sport\", \"Event\"],\n",
    "    value=\"Sport\",  # Default value\n",
    "    description='Select Sport/Event:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Create a text box for inputting the specific sport or event name (e.g., \"Boxing\")\n",
    "input_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type here',\n",
    "    description='Input specific Sport/Event:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Output widget to display results\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update and display the selection\n",
    "def on_button_click(b):\n",
    "    global model_data\n",
    "    '''\n",
    "    :param b: button click\n",
    "    :return: The selection for model\n",
    "    '''\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        selected_category = category_dropdown.value\n",
    "        user_input = input_box.value\n",
    "        print(f\"Selected Category: {selected_category}, Input: {user_input}\")\n",
    "\n",
    "        # Example usage of the selected value in your code\n",
    "        model_data = subset_enough_winners[subset_enough_winners[selected_category] == user_input]\n",
    "        display(model_data.head())\n",
    "\n",
    "# Create a button to trigger the selection\n",
    "submit_button = widgets.Button(\n",
    "    description='Submit',\n",
    "    disabled=False,\n",
    "    button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to submit selection',\n",
    ")\n",
    "\n",
    "# Attach the function to button click\n",
    "submit_button.on_click(on_button_click)\n",
    "\n",
    "# Display the widgets in the notebook\n",
    "display(category_dropdown)\n",
    "display(input_box)\n",
    "display(submit_button)\n",
    "display(output)\n",
    "#model_data = subset_enough_winners[subset_enough_winners[\"Sport\"] == \"Boxing\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropdown(description='Select Sport/Event:', options=('Sport', 'Event'), value='Sport')"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "435f2a91af0f4be3be528d43fc079a7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(value='', description='Input specific Sport/Event:', placeholder='Type here')"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62a675dd5b364dc69da60c6c7db9777b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle(), tooltip='Click to submit selection')"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b82dea9fa0394833b1ebf89b86989fe6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c05866277244485b169f1c57e546e5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "059e4e26",
   "metadata": {
    "id": "059e4e26",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:46:35.055071Z",
     "start_time": "2024-08-16T20:46:35.044997Z"
    }
   },
   "source": [
    "### Getting rid of Unecessary columns for building the models\n",
    "model_data = model_data.drop(columns = [\"Sport\", \"Event\", \"Year\"])\n",
    "# Making sure the size medals vs. non-medals is similar\n",
    "model_data = reduce_no_medal(model_data, len(model_data[model_data[\"Medal\"] == 1]))\n",
    "\n",
    "# Creating another model 1-hot encoding the country data\n",
    "one_hot_model = pd.get_dummies(model_data, columns=['NOC'], dtype = 'int')\n",
    "\n",
    "# Dropping the NOC column in the original data\n",
    "model_data = model_data.drop(columns = [\"NOC\"])"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "e1a1f24c",
   "metadata": {
    "id": "e1a1f24c",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:46:38.532455Z",
     "start_time": "2024-08-16T20:46:38.527541Z"
    }
   },
   "source": [
    "## The model without geographic influence\n",
    "\n",
    "X = model_data.drop(columns=['Medal'])\n",
    "Y = model_data['Medal']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state = 42)\n",
    "\n",
    "basic_data = (X_train, X_test, y_train, y_test)"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "4f7e9c69",
   "metadata": {
    "id": "4f7e9c69",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:46:42.618973Z",
     "start_time": "2024-08-16T20:46:42.611995Z"
    }
   },
   "source": [
    "#one_hot_model = one_hot_model.drop(columns = [\"Sport\", \"Event\", \"Year\"])\n",
    "\n",
    "### The model with Geographic influence\n",
    "one_hot_X = one_hot_model.drop(columns=['Medal'])\n",
    "one_hot_Y = one_hot_model['Medal']\n",
    "\n",
    "one_hot_X_train, one_hot_X_test, one_hot_y_train, one_hot_y_test = train_test_split(one_hot_X, one_hot_Y, test_size=0.1, random_state = 42)\n",
    "\n",
    "one_hot_data = (one_hot_X_train, one_hot_X_test, one_hot_y_train, one_hot_y_test)"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "c08985fa",
   "metadata": {
    "id": "c08985fa",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:46:49.326023Z",
     "start_time": "2024-08-16T20:46:49.323002Z"
    }
   },
   "source": [
    "def model_scorer(model_name, model, data):\n",
    "    (X_train, X_test, y_train, y_test) = data\n",
    "    model.fit(X_train, y_train)\n",
    "    return ((model_name, model.score(X_train, y_train), model.score(X_test, y_test)))"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "f4e7d936",
   "metadata": {
    "id": "f4e7d936",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:46:51.589052Z",
     "start_time": "2024-08-16T20:46:51.586599Z"
    }
   },
   "source": [
    "model_scores = []"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "8a08024f",
   "metadata": {
    "id": "8a08024f",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:47:00.134406Z",
     "start_time": "2024-08-16T20:47:00.076001Z"
    }
   },
   "source": [
    "dtc = DecisionTreeClassifier(max_leaf_nodes = 20)\n",
    "\n",
    "# Fit model to training data\n",
    "\n",
    "#dtc.fit(X_train, y_train)\n",
    "#print(\"training accuracy: {}| testing accuracy: {}\".format(round(dtc.score(X_train, y_train),2), round(dtc.score(X_test, y_test),2)))\n",
    "\n",
    "#print(export_text(dtc, feature_names = X.columns))\n",
    "model_scores.append(model_scorer(\"DTC\", dtc, basic_data))"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "61c812d6",
   "metadata": {
    "scrolled": false,
    "id": "61c812d6",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:47:08.266285Z",
     "start_time": "2024-08-16T20:47:08.251023Z"
    }
   },
   "source": [
    "one_hot_dtc = DecisionTreeClassifier(max_leaf_nodes = 20)\n",
    "\n",
    "# Fit model to training data\n",
    "\n",
    "#one_hot_dtc.fit(one_hot_X_train, one_hot_y_train)\n",
    "#print(\"training accuracy: {}| testing accuracy: {}\".format(round(one_hot_dtc.score(one_hot_X_train, one_hot_y_train),2), round(one_hot_dtc.score(one_hot_X_test, one_hot_y_test),2)))\n",
    "\n",
    "#print(export_text(one_hot_dtc, feature_names = one_hot_X.columns))\n",
    "model_scores.append(model_scorer(\"one_hot_DTC\", one_hot_dtc, one_hot_data))"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "33385b2a",
   "metadata": {
    "id": "33385b2a",
    "outputId": "46c123ee-f5cc-4322-de8e-66e90c97c5a7",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:49:58.456703Z",
     "start_time": "2024-08-16T20:49:58.292335Z"
    }
   },
   "source": [
    "#importing sklearn model constructors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "'''ADD SOME CODE HERE'''\n",
    "#creating logistic regression model\n",
    "lg = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"Logistic\", lg, basic_data))\n",
    "\n",
    "#one hot logistic regression\n",
    "one_hot_lg = LogisticRegression()\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"one_hot_Logistic\", lg, one_hot_data))"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "6266bbc1",
   "metadata": {
    "id": "6266bbc1",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:50:11.463513Z",
     "start_time": "2024-08-16T20:50:11.429873Z"
    }
   },
   "source": [
    "#creating LDA model\n",
    "lda = LinearDiscriminantAnalysis(store_covariance = True)\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"LDA\", lda, basic_data))\n",
    "\n",
    "#one hot version\n",
    "one_hot_lda = LinearDiscriminantAnalysis(store_covariance = True)\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"one_hot_LDA\", one_hot_lda, one_hot_data))\n"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "7525312d",
   "metadata": {
    "id": "7525312d",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:50:15.843547Z",
     "start_time": "2024-08-16T20:50:15.358293Z"
    }
   },
   "source": [
    "#creating random forest model\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"RFC\", rfc, basic_data))\n",
    "\n",
    "#one hot version\n",
    "one_hot_rfc = RandomForestClassifier()\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"one_hot_RFC\", one_hot_rfc, one_hot_data))\n",
    "\n",
    "#creating bagging model\n",
    "bc = BaggingClassifier()\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"Bagging\", bc, basic_data))\n",
    "\n",
    "#one hot version\n",
    "one_hot_bc = BaggingClassifier()\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"one_hot_Bagging\", one_hot_bc, one_hot_data))\n",
    "\n",
    "#creating boosting model\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"Boosting\", gbc, basic_data))\n",
    "\n",
    "#one hot version\n",
    "one_hot_gbc = GradientBoostingClassifier()\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"one_hot_Boosting\", one_hot_gbc, one_hot_data))"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "6e249847",
   "metadata": {
    "id": "6e249847",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:50:21.079163Z",
     "start_time": "2024-08-16T20:50:20.835716Z"
    }
   },
   "source": [
    "#creating svc model\n",
    "svc = SVC()\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"SVC\", svc, basic_data))\n",
    "\n",
    "#one hot version\n",
    "one_hot_svc = SVC()\n",
    "\n",
    "#saving results\n",
    "model_scores.append(model_scorer(\"one_hot_SVC\", one_hot_svc, one_hot_data))"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "8a180bb1",
   "metadata": {
    "id": "8a180bb1",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:50:24.492679Z",
     "start_time": "2024-08-16T20:50:24.489647Z"
    }
   },
   "source": [
    "model_scores = pd.DataFrame(model_scores, columns=['Model', 'Training Accuracy', 'Testing Accuracy'])"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "6d723f50",
   "metadata": {
    "id": "6d723f50",
    "outputId": "c90b925e-2007-463a-eead-334745227935",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:12:56.523090Z",
     "start_time": "2024-08-16T20:12:56.518890Z"
    }
   },
   "source": [
    "model_scores"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               Model  Training Accuracy  Testing Accuracy\n",
       "0                DTC           0.580581          0.576577\n",
       "1        one_hot_DTC           0.703704          0.657658\n",
       "2           Logistic           0.553554          0.549550\n",
       "3   one_hot_Logistic           0.713714          0.657658\n",
       "4                LDA           0.553554          0.558559\n",
       "5        one_hot_LDA           0.725726          0.603604\n",
       "6                RFC           0.920921          0.513514\n",
       "7        one_hot_RFC           0.997998          0.612613\n",
       "8            Bagging           0.899900          0.522523\n",
       "9    one_hot_Bagging           0.959960          0.630631\n",
       "10          Boosting           0.671672          0.495495\n",
       "11  one_hot_Boosting           0.759760          0.657658\n",
       "12               SVC           0.554555          0.567568\n",
       "13       one_hot_SVC           0.555556          0.567568"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC</td>\n",
       "      <td>0.580581</td>\n",
       "      <td>0.576577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one_hot_DTC</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.657658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.553554</td>\n",
       "      <td>0.549550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one_hot_Logistic</td>\n",
       "      <td>0.713714</td>\n",
       "      <td>0.657658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.553554</td>\n",
       "      <td>0.558559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one_hot_LDA</td>\n",
       "      <td>0.725726</td>\n",
       "      <td>0.603604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RFC</td>\n",
       "      <td>0.920921</td>\n",
       "      <td>0.513514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>one_hot_RFC</td>\n",
       "      <td>0.997998</td>\n",
       "      <td>0.612613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.899900</td>\n",
       "      <td>0.522523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one_hot_Bagging</td>\n",
       "      <td>0.959960</td>\n",
       "      <td>0.630631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Boosting</td>\n",
       "      <td>0.671672</td>\n",
       "      <td>0.495495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>one_hot_Boosting</td>\n",
       "      <td>0.759760</td>\n",
       "      <td>0.657658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.554555</td>\n",
       "      <td>0.567568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>one_hot_SVC</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.567568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "68824fe4",
   "metadata": {
    "id": "68824fe4",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:13:23.593322Z",
     "start_time": "2024-08-16T20:13:23.480799Z"
    }
   },
   "source": [
    "test_df = pd.read_csv(\"data/cvs\")\n",
    "test_boxing = test_df[test_df['Sport']==\"Boxing\"].drop(columns=[\"Year\", \"Season\", \"City\",\"Name\", \"Team\",\"Unnamed: 13\", \"Event\",\"Sport\",\"NOC\",\"Games\"] )\n",
    "test_boxing['Sex'] = test_boxing['Sex'].apply(lambda x: 0 if x == 'M' else 1)\n",
    "print(test_boxing.shape)\n",
    "predictions = lg.predict(test_boxing)\n",
    "predictions"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- NOC_AFG\n- NOC_AHO\n- NOC_ALB\n- NOC_ALG\n- NOC_AND\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m test_boxing[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSex\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m test_boxing[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSex\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(test_boxing\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m----> 5\u001B[0m predictions \u001B[38;5;241m=\u001B[39m lg\u001B[38;5;241m.\u001B[39mpredict(test_boxing)\n\u001B[1;32m      6\u001B[0m predictions\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:451\u001B[0m, in \u001B[0;36mLinearClassifierMixin.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;124;03mPredict class labels for samples in X.\u001B[39;00m\n\u001B[1;32m    439\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;124;03m    Vector containing the class labels for each sample.\u001B[39;00m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    450\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[0;32m--> 451\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecision_function(X)\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(scores\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    453\u001B[0m     indices \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(scores \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mint\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:432\u001B[0m, in \u001B[0;36mLinearClassifierMixin.decision_function\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    429\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    430\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[0;32m--> 432\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(X, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    433\u001B[0m scores \u001B[38;5;241m=\u001B[39m safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_\u001B[38;5;241m.\u001B[39mT, dense_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_\n\u001B[1;32m    434\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39mreshape(scores, (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,)) \u001B[38;5;28;01mif\u001B[39;00m scores\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m scores\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:579\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_data\u001B[39m(\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    510\u001B[0m     X\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    515\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params,\n\u001B[1;32m    516\u001B[0m ):\n\u001B[1;32m    517\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001B[39;00m\n\u001B[1;32m    518\u001B[0m \n\u001B[1;32m    519\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;124;03m        validated.\u001B[39;00m\n\u001B[1;32m    578\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 579\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_feature_names(X, reset\u001B[38;5;241m=\u001B[39mreset)\n\u001B[1;32m    581\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_tags()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires_y\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    582\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    583\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m estimator \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    584\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires y to be passed, but the target y is None.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    585\u001B[0m         )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:506\u001B[0m, in \u001B[0;36mBaseEstimator._check_feature_names\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m missing_names \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m unexpected_names:\n\u001B[1;32m    502\u001B[0m     message \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    503\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature names must be in the same order as they were in fit.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    504\u001B[0m     )\n\u001B[0;32m--> 506\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(message)\n",
      "\u001B[0;31mValueError\u001B[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- NOC_AFG\n- NOC_AHO\n- NOC_ALB\n- NOC_ALG\n- NOC_AND\n- ...\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "1d84b0e6",
   "metadata": {
    "id": "1d84b0e6",
    "ExecuteTime": {
     "end_time": "2024-08-16T20:52:02.325208Z",
     "start_time": "2024-08-16T20:52:02.148696Z"
    }
   },
   "source": [
    "test_boxing_one_hot = test_boxing = test_df[test_df['Sport']==\"Boxing\"].drop(columns=[\"Year\", \"Season\", \"City\",\"Name\", \"Team\",\"Unnamed: 13\", \"Event\",\"Sport\",\"Games\"] )\n",
    "test_boxing_one_hot = pd.get_dummies(test_boxing_one_hot, columns=['NOC'], dtype = 'int')\n",
    "list_of_col = list(one_hot_X_train.columns.values)\n",
    "for col in list_of_col:\n",
    "    test_boxing_one_hot[col] = 0\n",
    "\n",
    "test_boxing_one_hot = test_boxing_one_hot[one_hot_X_train.columns]\n",
    "\n",
    "predictions = one_hot_dtc.predict(test_boxing_one_hot)\n",
    "print(predictions)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n",
      "/var/folders/gg/qxtxkv2501v1x8qx_r4vgk_m0000gn/T/ipykernel_32315/2394861291.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_boxing_one_hot[col] = 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 124)) while a minimum of 1 is required by DecisionTreeClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[60], line 9\u001B[0m\n\u001B[1;32m      5\u001B[0m     test_boxing_one_hot[col] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      7\u001B[0m test_boxing_one_hot \u001B[38;5;241m=\u001B[39m test_boxing_one_hot[one_hot_X_train\u001B[38;5;241m.\u001B[39mcolumns]\n\u001B[0;32m----> 9\u001B[0m predictions \u001B[38;5;241m=\u001B[39m one_hot_dtc\u001B[38;5;241m.\u001B[39mpredict(test_boxing_one_hot)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(predictions)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:500\u001B[0m, in \u001B[0;36mBaseDecisionTree.predict\u001B[0;34m(self, X, check_input)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Predict class or regression value for X.\u001B[39;00m\n\u001B[1;32m    478\u001B[0m \n\u001B[1;32m    479\u001B[0m \u001B[38;5;124;03mFor a classification model, the predicted class for each sample in X is\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;124;03m    The predicted classes, or the predict values.\u001B[39;00m\n\u001B[1;32m    498\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    499\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 500\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_X_predict(X, check_input)\n\u001B[1;32m    501\u001B[0m proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtree_\u001B[38;5;241m.\u001B[39mpredict(X)\n\u001B[1;32m    502\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:460\u001B[0m, in \u001B[0;36mBaseDecisionTree._validate_X_predict\u001B[0;34m(self, X, check_input)\u001B[0m\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    459\u001B[0m     force_all_finite \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 460\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[1;32m    461\u001B[0m     X,\n\u001B[1;32m    462\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mDTYPE,\n\u001B[1;32m    463\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    464\u001B[0m     reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    465\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n\u001B[1;32m    466\u001B[0m )\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X) \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[1;32m    468\u001B[0m     X\u001B[38;5;241m.\u001B[39mindices\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc \u001B[38;5;129;01mor\u001B[39;00m X\u001B[38;5;241m.\u001B[39mindptr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc\n\u001B[1;32m    469\u001B[0m ):\n\u001B[1;32m    470\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo support for np.int64 index based sparse matrices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:604\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    602\u001B[0m         out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    603\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 604\u001B[0m     out \u001B[38;5;241m=\u001B[39m check_array(X, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[1;32m    606\u001B[0m     out \u001B[38;5;241m=\u001B[39m _check_y(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:969\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    967\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n\u001B[1;32m    968\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_samples \u001B[38;5;241m<\u001B[39m ensure_min_samples:\n\u001B[0;32m--> 969\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    970\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m sample(s) (shape=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) while a\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    971\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m minimum of \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m is required\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    972\u001B[0m             \u001B[38;5;241m%\u001B[39m (n_samples, array\u001B[38;5;241m.\u001B[39mshape, ensure_min_samples, context)\n\u001B[1;32m    973\u001B[0m         )\n\u001B[1;32m    975\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_features \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m    976\u001B[0m     n_features \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mValueError\u001B[0m: Found array with 0 sample(s) (shape=(0, 124)) while a minimum of 1 is required by DecisionTreeClassifier."
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "292bf4487c8e73bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
